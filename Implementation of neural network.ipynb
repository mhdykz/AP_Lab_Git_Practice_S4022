{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8JbgZRbchCX2lnnTvk+5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhdykz/AP_Lab_Git_Practice_S4022/blob/main/Implementation%20of%20neural%20network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "gCCgNSG82mmw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read train and test data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Checking data info\n",
        "print(\"Train Data Info:\")\n",
        "print(train_data.info())\n",
        "print(\"\\nTest Data Info:\")\n",
        "print(test_data.info())\n",
        "\n",
        "print(\"\\nTrain Data Sample:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nTest Data Sample:\")\n",
        "print(test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOWMyZx03LZo",
        "outputId": "6ab50e0a-e243-4a0e-cd70-34c3742741b2"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Test Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "None\n",
            "\n",
            "Train Data Sample:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Test Data Sample:\n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing data\n",
        "print(\"Missing values in each column:\")\n",
        "print(train_data.isnull().sum())\n",
        "print(test_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtgpiJfW32J6",
        "outputId": "d85b07a6-5ce1-4974-c240-f551114ccc89"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling missing values of 'Age' and 'Fare' columns with mean\n",
        "train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\n",
        "test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)\n",
        "\n",
        "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)\n",
        "test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\n",
        "\n",
        "# Filling 'Embarked' column with the mode\n",
        "train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)\n",
        "test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical columns to numeric\n",
        "train_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "test_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TOh3kHXk5Yv2"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "دلیل اصلی نرمال‌سازی:\n",
        "تفاوت در مقیاس ویژگی‌ها: داده‌های مختلف ممکن است مقادیر بسیار متفاوتی داشته باشند. مثلاً ستون Age (سن) می‌تواند مقادیری بین 0 تا 80 داشته باشد، در حالی که ستون Fare (هزینه بلیت) ممکن است مقادیری بین 0 تا چند صد داشته باشد. این تفاوت در مقیاس می‌تواند باعث شود که مدل به ویژگی‌هایی با مقیاس بزرگ‌تر حساس‌تر شود و ویژگی‌های کوچک‌تر را نادیده بگیرد.\n",
        "\n",
        "تسریع در همگرایی مدل: زمانی که ویژگی‌ها در مقیاس مشابهی قرار بگیرند، الگوریتم‌های بهینه‌سازی (مثل نزول گرادیان) سریع‌تر و با کارایی بهتری عمل می‌کنند. اگر مقیاس ویژگی‌ها متفاوت باشد، مدل ممکن است نیاز به تعداد بیشتری از گام‌های بهینه‌سازی داشته باشد تا به یک نتیجه خوب برسد.\n",
        "\n",
        "پیش‌فرض بسیاری از الگوریتم‌ها: بسیاری از الگوریتم‌های یادگیری ماشین فرض می‌کنند که داده‌ها دارای توزیعی نرمال هستند (میانگین 0 و واریانس 1). استانداردسازی به تنظیم داده‌ها در این توزیع کمک می‌کند.\n",
        "\n",
        "نرمال‌سازی چگونه انجام می‌شود؟\n",
        "در اینجا از استانداردسازی استفاده می‌کنیم، به این معنی که هر ویژگی به‌گونه‌ای تغییر می‌کند که دارای میانگین صفر و انحراف معیار یک باشد."
      ],
      "metadata": {
        "id": "1ooL_CjV77Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization of 'Age' and 'Fare'\n",
        "scaler = StandardScaler()\n",
        "train_data[['Age', 'Fare']] = scaler.fit_transform(train_data[['Age', 'Fare']])\n",
        "test_data[['Age', 'Fare']] = scaler.transform(test_data[['Age', 'Fare']])\n",
        "\n",
        "print(\"\\nData after preprocessing:\")\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo1kig6-6HNC",
        "outputId": "0ed639cb-2048-457a-e91e-c35da812b5d0"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after preprocessing:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name       Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris -0.592481      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  0.638789      1      0   \n",
            "2                             Heikkinen, Miss. Laina -0.284663      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.407926      1      0   \n",
            "4                           Allen, Mr. William Henry  0.407926      0      0   \n",
            "\n",
            "             Ticket      Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \n",
            "0         A/5 21171 -0.502445   NaN      True       False        True  \n",
            "1          PC 17599  0.786845   C85     False       False       False  \n",
            "2  STON/O2. 3101282 -0.488854   NaN     False       False        True  \n",
            "3            113803  0.420730  C123     False       False        True  \n",
            "4            373450 -0.486337   NaN      True       False        True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select input properties and labels\n",
        "Xtrain = train_data[['Pclass', 'Sex_male', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Q', 'Embarked_S']]\n",
        "Ytrain = train_data['Survived']\n",
        "Xtest = test_data[['Pclass', 'Sex_male', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Q', 'Embarked_S']]\n",
        "\n",
        "\n",
        "print(\"\\nFeature Matrix (Xtrain):\")\n",
        "print(Xtrain.head())\n",
        "print(\"\\nLabels (Ytrain):\")\n",
        "print(Ytrain.head())\n",
        "\n",
        "\n",
        "Xtrain = Xtrain.replace({True: 1, False: 0})\n",
        "Xtest = Xtest.replace({True: 1, False: 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoG7ccRR8NKF",
        "outputId": "68c66222-e36f-4d7f-e4a0-f6ef84a128dd"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Matrix (Xtrain):\n",
            "   Pclass  Sex_male       Age  SibSp  Parch      Fare  Embarked_Q  Embarked_S\n",
            "0       3      True -0.592481      1      0 -0.502445       False        True\n",
            "1       1     False  0.638789      1      0  0.786845       False       False\n",
            "2       3     False -0.284663      0      0 -0.488854       False        True\n",
            "3       1     False  0.407926      1      0  0.420730       False        True\n",
            "4       3      True  0.407926      0      0 -0.486337       False        True\n",
            "\n",
            "Labels (Ytrain):\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Survived, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، داده‌های آموزشی را به دو بخش ویژگی‌ها (Feature Matrix) و برچسب‌ها (Labels) تقسیم می‌کنیم. این کار به این دلیل انجام می‌شود که در الگوریتم‌های یادگیری ماشین، مدل از ویژگی‌ها برای یادگیری استفاده می‌کند و سپس برچسب‌ها را به عنوان خروجی پیش‌بینی می‌کند.\n",
        "\n",
        "جزئیات این مرحله:\n",
        "ویژگی‌ها (Xtrain):\n",
        "\n",
        "ویژگی‌ها همان فاکتورهایی هستند که مدل از آن‌ها برای پیش‌بینی استفاده می‌کند. در مسئله Titanic، این ویژگی‌ها می‌توانند مواردی مثل کلاس بلیت (Pclass)، جنسیت (Sex)، سن (Age)، تعداد اعضای خانواده همراه (SibSp و Parch) و سایر ویژگی‌ها باشند.\n",
        "هر کدام از این ستون‌ها به عنوان یک ورودی برای مدل استفاده می‌شود تا براساس این ویژگی‌ها پیش‌بینی کند که آیا یک مسافر زنده مانده یا نه.\n",
        "در این مرحله، ما چند ویژگی مهم را انتخاب کرده‌ایم تا به عنوان ورودی مدل استفاده شوند:\n",
        "Pclass: کلاس بلیت (1، 2 یا 3)\n",
        "Sex: جنسیت (0 برای مرد، 1 برای زن)\n",
        "Age: سن مسافر\n",
        "SibSp: تعداد اعضای خانواده همراه (خواهر و برادر، همسر)\n",
        "Parch: تعداد والدین یا فرزندان همراه\n",
        "Fare: هزینه بلیت\n",
        "Embarked_Q و Embarked_S: مبدا سفر (بندرهایی که مسافر سوار شده است)\n",
        "برچسب‌ها (Ytrain):\n",
        "\n",
        "برچسب‌ها مقادیری هستند که مدل باید آن‌ها را پیش‌بینی کند. در اینجا، برچسب‌ها همان Survived هستند که مشخص می‌کند آیا مسافر زنده مانده است یا نه. این ستون شامل مقادیر 0 (زنده نمانده) و 1 (زنده مانده) است.\n",
        "مدل با استفاده از ویژگی‌ها سعی می‌کند برچسب درست را پیش‌بینی کند."
      ],
      "metadata": {
        "id": "h6sFLnGT9w0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays for neural network\n",
        "Xtrain = np.array(Xtrain, dtype=float)\n",
        "Xtest = np.array(Xtest, dtype=float)\n",
        "Ytrain = np.array(Ytrain).reshape(-1, 1)  # Ensure Ytrain is reshaped to (m, 1)\n",
        "\n",
        "print(\"Type of Xtrain:\", type(Xtrain))\n",
        "print(\"Xtrain shape:\", Xtrain.shape)\n",
        "print(\"First few rows of Xtrain:\", Xtrain[:5])\n",
        "\n",
        "print(\"Checking for NaN values in Xtrain:\")\n",
        "print(np.isnan(Xtrain).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyn2rEhY83c1",
        "outputId": "e5079e15-3d0b-4ebb-9bc0-48c7c495d395"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of Xtrain: <class 'numpy.ndarray'>\n",
            "Xtrain shape: (891, 8)\n",
            "First few rows of Xtrain: [[ 3.          1.         -0.5924806   1.          0.         -0.50244517\n",
            "   0.          1.        ]\n",
            " [ 1.          0.          0.63878901  1.          0.          0.78684529\n",
            "   0.          0.        ]\n",
            " [ 3.          0.         -0.2846632   0.          0.         -0.48885426\n",
            "   0.          1.        ]\n",
            " [ 1.          0.          0.40792596  1.          0.          0.42073024\n",
            "   0.          1.        ]\n",
            " [ 3.          1.          0.40792596  0.          0.         -0.48633742\n",
            "   0.          1.        ]]\n",
            "Checking for NaN values in Xtrain:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، برای شروع آموزش شبکه عصبی، باید وزن‌ها و بایاس‌ها را مقداردهی اولیه کنیم. شبکه‌های عصبی برای یادگیری، به وزن‌ها و بایاس‌ها در لایه‌های مختلف نیاز دارند. این وزن‌ها و بایاس‌ها در ابتدا به صورت تصادفی مقداردهی می‌شوند و سپس در طول فرآیند آموزش با استفاده از پس‌انتشار خطا (Backpropagation) و نزول گرادیان (Gradient Descent) به‌روزرسانی می‌شوند.\n",
        "\n",
        "مفاهیم کلیدی:\n",
        "وزن‌ها (Weights):\n",
        "\n",
        "وزن‌ها مشخص می‌کنند که چقدر یک ویژگی ورودی یا خروجی یک نورون بر نورون‌های بعدی تأثیر می‌گذارد. به عبارت دیگر، وزن‌ها مشخص می‌کنند که هر ورودی چه میزان اهمیت دارد.\n",
        "در شبکه عصبی، هر اتصال بین دو نورون دارای یک وزن است.\n",
        "بایاس‌ها (Biases):\n",
        "\n",
        "بایاس‌ها به مدل کمک می‌کنند تا بتواند در صورت نیاز، شیب تابع فعال‌سازی را تغییر دهد و از صرفاً یک خط مستقیم جلوگیری کند. این باعث انعطاف‌پذیری بیشتر مدل در یادگیری الگوهای پیچیده می‌شود.\n",
        "بایاس‌ها معمولاً به عنوان یک عدد اضافه می‌شوند تا مدل بتواند به راحتی مقادیر خروجی را تغییر دهد.\n",
        "معماری شبکه:\n",
        "ما در اینجا یک شبکه عصبی با یک لایه پنهان و یک لایه خروجی داریم:\n",
        "\n",
        "لایه ورودی: شامل تعداد ویژگی‌های ورودی است که از دیتاست می‌آیند. برای مثال، ما 8 ویژگی داریم (مثل Age، Fare و غیره).\n",
        "لایه پنهان: شامل نورون‌هایی است که بین ورودی و خروجی قرار دارند. در اینجا ما 4 نورون در لایه پنهان داریم.\n",
        "لایه خروجی: شامل یک نورون است که نتیجه نهایی (پیش‌بینی زنده ماندن یا نه) را می‌دهد. چون این یک مسئله دسته‌بندی دو مقداری است (زنده ماندن یا نماندن)، تنها یک نورون در لایه خروجی داریم.\n",
        "جزئیات کد:\n",
        "تعداد نورون‌ها در لایه‌های مختلف:\n",
        "\n",
        "input_size: تعداد ویژگی‌ها در ورودی (در اینجا 8 ویژگی است).\n",
        "hidden_size: تعداد نورون‌ها در لایه پنهان (در اینجا 4 نورون در لایه پنهان انتخاب کرده‌ایم).\n",
        "output_size: تعداد نورون‌ها در لایه خروجی (در اینجا 1، زیرا خروجی ما تنها می‌گوید آیا مسافر زنده مانده یا نه).\n",
        "مقداردهی اولیه وزن‌ها:\n",
        "\n",
        "وزن‌های بین لایه ورودی و پنهان (W1) به صورت تصادفی با استفاده از تابع np.random.randn مقداردهی می‌شوند. این مقادیر تصادفی کوچک به مدل کمک می‌کنند که از یک شروع کاملاً متقارن جلوگیری شود.\n",
        "به همین شکل، وزن‌های بین لایه پنهان و لایه خروجی (W2) نیز به صورت تصادفی مقداردهی می‌شوند.\n",
        "مقداردهی اولیه بایاس‌ها:\n",
        "\n",
        "بایاس‌های هر لایه (b1 و b2) در ابتدا به صورت صفر مقداردهی شده‌اند. این مقادیر در طول آموزش به‌روزرسانی خواهند شد."
      ],
      "metadata": {
        "id": "ALsDNNg-ADxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural network initialization\n",
        "input_size = Xtrain.shape[1]  # Number of input features\n",
        "hidden_size = 4  # The number of neurons in the hidden layer\n",
        "output_size = 1  # Number of neurons in the output layer (binary prediction)\n",
        "\n",
        "np.random.seed(42)\n",
        "W1 = np.random.randn(input_size, hidden_size) * 0.01  # Weights between input and hidden layer\n",
        "b1 = np.zeros((1, hidden_size))  # Biases of hidden layer\n",
        "W2 = np.random.randn(hidden_size, output_size) * 0.01  # Weights between hidden and output layer\n",
        "b2 = np.zeros((1, output_size))  # Biases of output layer"
      ],
      "metadata": {
        "id": "frD9DW-g91Ne"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، یک تابع برای عبور رو به جلو ایجاد می‌کنیم که با استفاده از ورودی‌ها، خروجی هر لایه را محاسبه می‌کند. این تابع از فرمول‌هایی که قبلاً در تحقیق قبل بیان کردیم استفاده می‌کند."
      ],
      "metadata": {
        "id": "WqD36iMvGezk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural network functions\n",
        "def forward_pass(X, W1, b1, W2, b2):\n",
        "    \"\"\"\n",
        "    Forward pass of the neural network\n",
        "    \"\"\"\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = np.tanh(z1)  # Ensure input is properly normalized and structured\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    y_hat = 1 / (1 + np.exp(-z2))  # Sigmoid output\n",
        "    return y_hat, z1, a1"
      ],
      "metadata": {
        "id": "SwGOAS0-GjNN"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، یک تابع برای پس‌انتشار خطا پیاده‌سازی می‌کنیم. این تابع گرادیان‌های مورد نیاز برای به‌روزرسانی وزن‌ها و بایاس‌ها را محاسبه می‌کند.\n",
        "اینجا از فرمول‌هایی که قبلاً در تحقیق قبل بیان کردیم استفاده می‌شود\n"
      ],
      "metadata": {
        "id": "4u6zQjlgHtMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, y_hat, z1, a1, W2):\n",
        "    \"\"\"\n",
        "    Backpropagation to compute gradients\n",
        "    \"\"\"\n",
        "    m = X.shape[0]  # Number of samples\n",
        "\n",
        "    dz2 = (y_hat - y).reshape(m, 1)  # Ensure dz2 is (m, 1)\n",
        "\n",
        "    # Compute the gradients of the output layer\n",
        "    dW2 = np.dot(a1.T, dz2) / m  # shape of dW2 should be (hidden_size, output_size)\n",
        "    db2 = np.sum(dz2, axis=0, keepdims=True) / m  # shape of db2 should be (1, output_size)\n",
        "\n",
        "    # Derivative relative to the hidden layer\n",
        "    dz1 = np.dot(dz2, W2.T) * (1 - np.tanh(z1) ** 2)  # shape of dz1 should be (m, hidden_size)\n",
        "\n",
        "    # Compute the gradients of the hidden layer\n",
        "    dW1 = np.dot(X.T, dz1) / m  # shape of dW1 should be (input_size, hidden_size)\n",
        "    db1 = np.sum(dz1, axis=0, keepdims=True) / m  # shape of db1 should be (1, hidden_size)\n",
        "\n",
        "    return dW1, db1, dW2, db2\n",
        "\n"
      ],
      "metadata": {
        "id": "7lKHPBOXIChJ"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، تابعی برای به‌روزرسانی وزن‌ها و بایاس‌ها با استفاده از گرادیان‌ها و نزول گرادیان پیاده‌سازی می‌کنیم."
      ],
      "metadata": {
        "id": "arCgGbeZdYxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
        "    \"\"\"\n",
        "    Update weights and biases using gradient descent\n",
        "    \"\"\"\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "    return W1, b1, W2, b2\n"
      ],
      "metadata": {
        "id": "oBNt21nAdZ7R"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "تابع پیش‌بینی با استفاده از عبور رو به جلو اجرا می‌شود تا خروجی شبکه برای ورودی جدید محاسبه شود.\n",
        "از تابع forward_pass برای محاسبه خروجی شبکه استفاده می‌کنیم.\n",
        "سپس خروجی‌ها (مقادیر سیگموید) را با 0.5 مقایسه می‌کنیم تا پیش‌بینی‌های نهایی (0 یا 1) به دست آید.\n",
        "\n"
      ],
      "metadata": {
        "id": "RyBDUC_bdwKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, W1, b1, W2, b2):\n",
        "    \"\"\"\n",
        "    Predict output for input data X\n",
        "    \"\"\"\n",
        "    y_hat, _, _ = forward_pass(X, W1, b1, W2, b2)\n",
        "    predictions = (y_hat > 0.5).astype(int)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "L12EaSbpd3R-"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، تمامی تابع‌هایی که قبلاً پیاده‌سازی کردیم (عبور رو به جلو، پس‌انتشار خطا و به‌روزرسانی وزن‌ها) را در یک تابع جامع قرار می‌دهیم که مدل را برای تعداد مشخصی از تکرارها آموزش می‌دهد و خطا را در هر تکرار محاسبه می‌کند. همچنین در پایان، پیش‌بینی‌های مدل برای مجموعه تست را در یک فایل CSV ذخیره می‌کنیم.\n",
        "\n",
        "مراحل پیاده‌سازی:\n",
        "\n",
        "ورودی‌ها: Xtrain, Ytrain, Xtest, num_iterations, learning_rate\n",
        "\n",
        "در هر تکرار:\n",
        "عبور رو به جلو: محاسبه خروجی شبکه با استفاده از داده‌های آموزشی.\n",
        "\n",
        "پس‌انتشار خطا: محاسبه گرادیان‌ها.\n",
        "به‌روزرسانی وزن‌ها و بایاس‌ها: به‌روزرسانی پارامترها با استفاده از گرادیان‌ها.\n",
        "\n",
        "ذخیره خطا: محاسبه و ثبت خطا برای داده‌های آموزشی."
      ],
      "metadata": {
        "id": "cnUt_KNneIcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(Xtrain, Ytrain, Xtest, num_iterations, learning_rate):\n",
        "    \"\"\"\n",
        "    Train the network and evaluate it\n",
        "    \"\"\"\n",
        "    input_size = Xtrain.shape[1]\n",
        "    hidden_size = 4\n",
        "    output_size = 1\n",
        "    np.random.seed(42)\n",
        "    W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
        "    b1 = np.zeros((1, hidden_size))\n",
        "    W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
        "    b2 = np.zeros((1, output_size))\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        y_hat, z1, a1 = forward_pass(Xtrain, W1, b1, W2, b2)\n",
        "        loss = np.mean(-Ytrain * np.log(y_hat) - (1 - Ytrain) * np.log(1 - y_hat))\n",
        "        losses.append(loss)\n",
        "\n",
        "        dW1, db1, dW2, db2 = backpropagation(Xtrain, Ytrain, y_hat, z1, a1, W2)\n",
        "        W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
        "\n",
        "    predictions = predict(Xtest, W1, b1, W2, b2)\n",
        "    submission = pd.DataFrame({\n",
        "        \"PassengerId\": np.arange(1, len(predictions) + 1),\n",
        "        \"Survived\": predictions.flatten()\n",
        "    })\n",
        "    submission.to_csv(\"titanic_predictions.csv\", index=False)\n",
        "    return predictions, losses"
      ],
      "metadata": {
        "id": "YQYCbnXhj6Jy"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "مقداردهی اولیه: وزن‌ها و بایاس‌ها به‌طور تصادفی مقداردهی می‌شوند.\n",
        "\n",
        "حلقه آموزش: شبکه عصبی برای تعداد مشخصی از تکرارها آموزش داده می‌شود. در هر تکرار، عملیات عبور رو به جلو، پس‌انتشار خطا و به‌روزرسانی پارامترها انجام می‌شود.\n",
        "\n",
        "ثبت خطا: در هر تکرار، خطا محاسبه و ذخیره می‌شود تا بتوانیم روند کاهش خطا را مشاهده کنیم.\n",
        "\n",
        "پیش‌بینی برای مجموعه تست: در پایان، پیش‌بینی‌های مدل برای مجموعه تست محاسبه و در فایل CSV ذخیره می‌شود.\n"
      ],
      "metadata": {
        "id": "KaRkxfidmgSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "predictions, losses = train_and_evaluate(Xtrain, Ytrain, Xtest, num_iterations=1000, learning_rate=0.01)\n",
        "\n",
        "# Save predictions to CSV file\n",
        "submission = pd.DataFrame({\n",
        "    \"PassengerId\": test_data['PassengerId'],\n",
        "    \"Survived\": predictions.flatten()\n",
        "})\n",
        "\n",
        "submission.to_csv('titanic_predictions.csv', index=False)\n",
        "\n",
        "print(\"File saved as titanic_predictions.csv\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('titanic_predictions.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "aTmwss5JoNN4",
        "outputId": "815aaafb-527b-4183-fb2a-f4107f85bb51"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 0.6931\n",
            "Iteration 100, Loss: 0.6822\n",
            "Iteration 200, Loss: 0.6754\n",
            "Iteration 300, Loss: 0.6710\n",
            "Iteration 400, Loss: 0.6677\n",
            "Iteration 500, Loss: 0.6650\n",
            "Iteration 600, Loss: 0.6625\n",
            "Iteration 700, Loss: 0.6598\n",
            "Iteration 800, Loss: 0.6569\n",
            "Iteration 900, Loss: 0.6536\n",
            "File saved as titanic_predictions.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a41d9ce-6daf-4f59-ab27-591f32611250\", \"titanic_predictions.csv\", 2839)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}